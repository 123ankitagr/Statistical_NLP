{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNLP Assn 3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1rBvjvtYN9Z",
        "colab_type": "text"
      },
      "source": [
        "# **SNLP Assignment 3**\n",
        "\n",
        "**Team Members:**\n",
        "\n",
        "\n",
        "*   Ankit Agrawal - 2581532\n",
        "*   Akshay Joshi - 2581346\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqlZJE8UYVwF",
        "colab_type": "text"
      },
      "source": [
        "**Alternatively, the notebook could be run on Google Colab: https://colab.research.google.com/drive/1IUoeAy9zh_msvLE8EjPqU6VnL7BT_4Op?usp=sharing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGnMm_KBbDLG",
        "colab_type": "code",
        "outputId": "4094fbd0-d983-4a1c-fe26-83244606b36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#The Brown corpus from NLTK is pre-tokenized and tagged out of the box\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import nltk\n",
        "import math\n",
        "nltk.download('brown')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJLvRFrMw-q",
        "colab_type": "code",
        "outputId": "96008f34-3d39-45e6-87af-df54b0cfa4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#brown.words() returns an iterable list of tokenized words from the raw corpus\n",
        "#Also I couldn't find the un-tokenized/untagged version of Brown corpus from NLTK\n",
        "#Removing blank spaces/special characters (if any) & coverting the words in the list to lowercase\n",
        "\n",
        "pro_words = []\n",
        "for i in brown.words():\n",
        "  text1 = i.translate(str.maketrans('', '', string.punctuation))\n",
        "  text2 = text1.translate(str.maketrans('','','.,一■–ー\\t'))\n",
        "  text3 = text2.translate(str.maketrans('','','\\n'))\n",
        "  text4 = text3.lower()\n",
        "  pro_words.append(text4)\n",
        "print(pro_words[:250])\n",
        "\n",
        "#Removing left out blank strings from the list of words\n",
        "final_words = []\n",
        "for j in pro_words:\n",
        "  if (j != \"\"):\n",
        "    final_words.append(j)\n",
        "print(final_words[:250])\n",
        "\n",
        "with open('/content/Brown.txt', 'w') as ff:\n",
        "  for items in final_words:\n",
        "    ff.write(\"%s \\n\" %items)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlantas', 'recent', 'primary', 'election', 'produced', '', 'no', 'evidence', '', 'that', 'any', 'irregularities', 'took', 'place', '', 'the', 'jury', 'further', 'said', 'in', 'termend', 'presentments', 'that', 'the', 'city', 'executive', 'committee', '', 'which', 'had', 'overall', 'charge', 'of', 'the', 'election', '', '', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', '', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '', 'the', 'septemberoctober', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', '', 'irregularities', '', 'in', 'the', 'hardfought', 'primary', 'which', 'was', 'won', 'by', 'mayornominate', 'ivan', 'allen', 'jr', '', '', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', '', '', 'the', 'jury', 'said', '', '', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', '', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', '', '', 'the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgias', 'registration', 'and', 'election', 'laws', '', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', '', '', 'it', 'recommended', 'that', 'fulton', 'legislators', 'act', '', 'to', 'have', 'these', 'laws', 'studied', 'and', 'revised', 'to', 'the', 'end', 'of', 'modernizing', 'and', 'improving', 'them', '', '', 'the', 'grand', 'jury', 'commented', 'on', 'a', 'number', 'of', 'other', 'topics', '', 'among', 'them', 'the', 'atlanta', 'and', 'fulton', 'county', 'purchasing', 'departments', 'which', 'it', 'said', '', 'are', 'well', 'operated', 'and', 'follow', 'generally', 'accepted', 'practices', 'which', 'inure', 'to', 'the', 'best', 'interest', 'of', 'both', 'governments', '', '', 'merger', 'proposed', 'however', '', 'the', 'jury', 'said', 'it', 'believes', '', 'these', 'two', 'offices', 'should', 'be', 'combined', 'to', 'achieve', 'greater']\n",
            "['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlantas', 'recent', 'primary', 'election', 'produced', 'no', 'evidence', 'that', 'any', 'irregularities', 'took', 'place', 'the', 'jury', 'further', 'said', 'in', 'termend', 'presentments', 'that', 'the', 'city', 'executive', 'committee', 'which', 'had', 'overall', 'charge', 'of', 'the', 'election', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', 'the', 'septemberoctober', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', 'irregularities', 'in', 'the', 'hardfought', 'primary', 'which', 'was', 'won', 'by', 'mayornominate', 'ivan', 'allen', 'jr', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', 'the', 'jury', 'said', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', 'the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgias', 'registration', 'and', 'election', 'laws', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', 'it', 'recommended', 'that', 'fulton', 'legislators', 'act', 'to', 'have', 'these', 'laws', 'studied', 'and', 'revised', 'to', 'the', 'end', 'of', 'modernizing', 'and', 'improving', 'them', 'the', 'grand', 'jury', 'commented', 'on', 'a', 'number', 'of', 'other', 'topics', 'among', 'them', 'the', 'atlanta', 'and', 'fulton', 'county', 'purchasing', 'departments', 'which', 'it', 'said', 'are', 'well', 'operated', 'and', 'follow', 'generally', 'accepted', 'practices', 'which', 'inure', 'to', 'the', 'best', 'interest', 'of', 'both', 'governments', 'merger', 'proposed', 'however', 'the', 'jury', 'said', 'it', 'believes', 'these', 'two', 'offices', 'should', 'be', 'combined', 'to', 'achieve', 'greater', 'efficiency', 'and', 'reduce', 'the', 'cost', 'of', 'administration', 'the', 'city', 'purchasing', 'department', 'the', 'jury', 'said', 'is', 'lacking', 'in', 'experienced', 'clerical', 'personnel', 'as', 'a', 'result', 'of', 'city', 'personnel', 'policies', 'it', 'urged', 'that', 'the']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSepfL3cfrYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculating the count of all the words in the brown corpus\n",
        "freq = []\n",
        "freq = [final_words.count(w) for w in final_words]\n",
        "print(freq)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxnKPNSzcI4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Conditional Probability Distribution, Prob Distribution plot & Expectation w.r.t \"in\"\n",
        "#Building a Uni-gram model to compute CPD of indicvidual word w.r.t the condition that the preceding word is \"in\"\n",
        "#Formula used to compute CPD: (Count of word appearing after \"in\" / Count of word in corpus)\n",
        "\n",
        "k = 1\n",
        "counts = 0\n",
        "in_list = []\n",
        "for index, item in enumerate(final_words):\n",
        "  if (final_words[index-1] and item == \"in\"):\n",
        "    counts += 1\n",
        "    cpd = counts / final_words.count(item)\n",
        "    in_list.append((item, cpd))\n",
        "\n",
        "#Plot Frequency/Probability distribution for Top-20 tokens in the distribution\n",
        "in_list.sort()\n",
        "in_list.reverse()\n",
        "\n",
        "in_result = []\n",
        "for i in range(min(20, len(in_list))):\n",
        "  n, m = in_list[i]\n",
        "  in_result.append((m, n))\n",
        "\n",
        "#Plotting the probabilty distribution of Top 20 tokens in \"in\" distribution\n",
        "plt.hist(in_result['n'], color = 'red', edgecolor = 'black', bins = int(2000/15))\n",
        "plt.title('Probability Plot of Top 20 words of \"in\" distribution')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Probablity')\n",
        "\n",
        "#Calculating the expectations of the distribution\n",
        "expected_in = math.log2(sum(in_result))\n",
        "expected_in *= -1\n",
        "print(expected_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izDrJJjLCz0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Conditional Probability Distribution, Prob Distribution plot & Expectation w.r.t \"in\"\n",
        "#Building a Uni-gram model to compute CPD of indicvidual word w.r.t the condition that the preceding word is \"the\"\n",
        "#Formula used to compute CPD: (Count of word appearing after \"the\" / Count of word in corpus)\n",
        "\n",
        "k = 1\n",
        "counts = 0\n",
        "the_list = []\n",
        "for index, item in enumerate(final_words):\n",
        "  if (final_words[index-1] and item == \"the\"):\n",
        "    counts += 1\n",
        "    cpd = counts / final_words.count(item)\n",
        "    the_list.append((item, cpd))\n",
        "\n",
        "#Plot Frequency/Probability distribution for Top-20 tokens in the distribution\n",
        "the_list.sort()\n",
        "the_list.reverse()\n",
        "\n",
        "the_result = []\n",
        "for i in range(min(20, len(the_list))):\n",
        "  n, m = the_list[i]\n",
        "  the_result.append((m, n))\n",
        "\n",
        "#Plotting the probabilty distribution of Top 20 tokens in \"the\" distribution\n",
        "plt.hist(the_result['n'], color = 'red', edgecolor = 'black', bins = int(2000/15))\n",
        "plt.title('Probability Plot of Top 20 words of \"the\" distribution')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Probablity')\n",
        "\n",
        "#Calculating the expectations of the distribution\n",
        "expected_the = math.log2(sum(the_result))\n",
        "expected_the *= -1\n",
        "print(expected_the)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}